---
title: 机器学习（二）：绪论
date: 2025-05-18 14:31:14
tags:
  - 机器学习
  - Machine Learning
  - 高斯分布
  - 边缘概率分布
  - 条件概率分布
  - 舒尔补
categories:
  - AI
---

# 基本的数学知识

这一部分笔记主要学习高斯分布的联合概率分布、边缘概率和条件概率分布的求解过程。

## 高斯分布的边缘概率分布和条件概率分布

首先再回顾一下$p$维高斯分布的表达式：
$$
\begin{equation}
    X \sim N(\mu, \Sigma)=p(X)=\frac{1}{(2 \pi)^{\frac{p}{2}}|\Sigma|^{\frac{1}{2}}} \exp \left[-\frac{1}{2}(X-\mu)^{\top} \Sigma^{-1}(X-\mu)\right]
\end{equation}
$$

其中，
$$
\begin{equation}
    X =
    \begin{bmatrix}
        \begin{array}{l} x_1 \\ x_2 \\ \vdots \\ x_p \end{array}
    \end{bmatrix},
    \mu =
    \begin{bmatrix}
        \mu_1 \\ \mu_2 \\ \vdots \\ \mu_p
    \end{bmatrix},
    \Sigma =
    \begin{bmatrix}
        \sigma_{11} & \sigma_{12} & \cdots & \sigma_{1 p} \\
        \sigma_{21} & \sigma_{22} & \cdots & \sigma_{2 p} \\
        \vdots & \vdots & \ddots & \vdots \\
        \sigma_{p 1} & \sigma_{p 2} & \cdots & \sigma_{p p}
    \end{bmatrix}
\end{equation}
$$

在求边缘概率分布和条件概率分布时还需要用到2条定理。

!!! Note 定理一
    $X \sim N(\mu, \Sigma) \Longrightarrow A X+B \sim N(A \mu+B, A \Sigma A^{\top})$

!!! Note 定理二
    如果 $X \sim N(\mu, \Sigma)$，则 $M X \perp N X \Longleftrightarrow M \Sigma N^{\top}=0$。

    其中，符号$\perp$表示相互独立的含义。

### 边缘概率分布

式(1)是随机变量$x_1$到$x_p$的联合概率分布，现在我们将随机变量$X$分成$x_a$和$x_b$两部分，即：
$$
\begin{equation}
    X = \begin{bmatrix}
        x_a \\ x_b
    \end{bmatrix},
    x_a = \begin{bmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_m
    \end{bmatrix}_{(m \times 1)},
    x_b = \begin{bmatrix}
        x_{m+1} \\ x_{m+2} \\ \vdots \\ x_p
    \end{bmatrix}_{(n \times 1)},
    m + n = p
\end{equation}
$$

根据均值和协方差矩阵的定义，$\mu$和$\Sigma$可以做如下切分：
$$
\begin{equation}
    \mu = \begin{bmatrix}
        \mu_a \\ \mu_b
    \end{bmatrix},
    \Sigma = \begin{bmatrix}
        \Sigma_{aa} & \Sigma_{ab} \\
        \Sigma_{ba} & \Sigma_{bb}
    \end{bmatrix}
\end{equation}
$$

根据上面提到的两条定理，可以求出边缘概率密度$P(x_a)$，具体推导过程如下。

根据式(3)可知：
$$
\begin{equation}
    x_a = \begin{bmatrix}
        I_{(m \times m)} & 0 \end{bmatrix}
    \begin{bmatrix}
        x_a \\ x_b
    \end{bmatrix} =
    \begin{bmatrix}
        I_{(m \times m)} & 0
    \end{bmatrix} X
\end{equation}
$$

根据定理一可得：
$$
\begin{equation}
    \begin{aligned}
        \mathbb{E}[x_a] &= \begin{bmatrix}
                I_{(m \times m)} & 0
            \end{bmatrix} \mu =
            \begin{bmatrix}
                I_{(m \times m)} & 0
            \end{bmatrix}
            \begin{bmatrix}
                \mu_a \\ \mu_b
            \end{bmatrix}
            = \mu_a \\
        \mathbb{D}[x_a] &= \begin{bmatrix}
            I_{(m \times m)} & 0
        \end{bmatrix} \Sigma
        \begin{bmatrix}
            I_{(m \times m)} & 0
        \end{bmatrix}^{\top} \\
        &= \begin{bmatrix}
            I_{(m \times m)} & 0
        \end{bmatrix}
        \begin{bmatrix}
            \Sigma_{aa} & \Sigma_{ab} \\
            \Sigma_{ba} & \Sigma_{bb}
        \end{bmatrix}
        \begin{bmatrix}
            I_{(m \times m)} \\ 0
        \end{bmatrix} \\
        &= \Sigma_{aa}
    \end{aligned}
\end{equation}
$$

因此，最终可以得到$x_a$的边缘概率分布：
$$
\begin{equation}
    \boxed{x_a \sim N(\mu_a, \Sigma_{aa})}
\end{equation}
$$

同理可得$x_b$的边缘概率分布：
$$
\begin{equation}
    \boxed{x_b \sim N(\mu_b, \Sigma_{bb})}
\end{equation}
$$

### 条件概率分布

根据式(3)的分割，我们还希望求出条件概率分布$P(x_a|x_b)$和$P(x_b|x_a)$。但相比于边缘概率分布，直接求解条件概率分布相对较复杂，需要使用构造法求解。

首先需要先构造一个特殊的随机变量，这里记作$x_{b \cdot a}$，
$$
\begin{equation}
    x_{b \cdot a} = x_b - \Sigma_{ba} \Sigma_{aa}^{-1} x_a \Longrightarrow x_b = x_{b \cdot a} + \Sigma_{ba} \Sigma_{aa}^{-1} x_a
\end{equation}
$$

所以，$x_{b \cdot a}$可以表达为：
$$
\begin{equation}
    x_{b \cdot a} = \begin{bmatrix}
        -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
    \end{bmatrix}
    \begin{bmatrix}
        x_a \\ x_b
    \end{bmatrix} =
    \begin{bmatrix}
        -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
    \end{bmatrix} X
\end{equation}
$$

根据定理一可以得到$x_{b \cdot a}$的均值：
$$
\begin{equation}
    \begin{aligned}
        \mathbb{E}[x_{b \cdot a}] &= \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix} \mu =
        \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix}
        \begin{bmatrix}
            \mu_a \\ \mu_b
        \end{bmatrix} \\
        &= -\Sigma_{ba} \Sigma_{aa}^{-1} \mu_a + \mu_b
    \end{aligned}
\end{equation}
$$

为了方便，我们把$\mathbb{E}[x_{b \cdot a}]$记为$\mu_{b \cdot a}$，即
$$
\begin{equation}
    \boxed{\mu_{b \cdot a} = \mathbb{E}[x_{b \cdot a}] = -\Sigma_{ba} \Sigma_{aa}^{-1} \mu_a + \mu_b}
\end{equation}
$$

根据定理一同样可以得到$x_{b \cdot a}$的方差：
$$
\begin{equation}
    \begin{aligned}
        \mathbb{D}[x_{b \cdot a}] &=
        \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix} \Sigma
        \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix}^{\top} \\
        &= \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix}
        \begin{bmatrix}
            \Sigma_{aa} & \Sigma_{ab} \\
            \Sigma_{ba} & \Sigma_{bb}
        \end{bmatrix}
        \begin{bmatrix}
            -(\Sigma_{aa}^{-1})^{\top} (\Sigma_{ba}^{\top}) \\ I_n
        \end{bmatrix} \\
        &= \Sigma_{bb} - \Sigma_{ba} \Sigma_{aa}^{-1} \Sigma_{ab}
    \end{aligned}
\end{equation}
$$

同样为了方便，我们把$\mathbb{D}[x_{b \cdot a}]$记为$\Sigma_{bb \cdot a}$，即
$$
\begin{equation}
    \boxed{\Sigma_{bb \cdot a} = \mathbb{D}[x_{b \cdot a}] = \Sigma_{bb} - \Sigma_{ba} \Sigma_{aa}^{-1} \Sigma_{ab}}
\end{equation}
$$

最终，可以得到这个特殊的随机变量$x_{b \cdot a}$服从如下分布：
$$
\begin{equation}
    \boxed{x_{b \cdot a} \sim N(\mu_{b \cdot a}, \Sigma_{bb \cdot a})}
\end{equation}
$$

这里顺便提及一下，从线性代数的角度看，$\Sigma_{bb \cdot a}$其实被称为$\Sigma_{aa}$在$\Sigma$中的舒尔补。

!!! note 舒尔补公式
    将$(n \times n)$的矩阵$M$写成分块形式，如式(16)所示。其中，$A$、$D$为方阵。
    - 若$A$为非奇异矩阵，则$A$在$M$中的舒尔补为$D - C A^{-1} B$。
    - 若$D$为非奇异矩阵，则$D$在$M$中的舒尔补为$A - B D^{-1} C$。

因为Hexo警示块中矩阵渲染的问题，所以把$M$放这里：
$$
\begin{equation}
    M =
    \begin{bmatrix}
        A & B \\ C & D
    \end{bmatrix}
\end{equation}
$$

上面，我们已经求出了特殊变量$x_{b \cdot a}$服从的分布，接下来还需要用到$x_{b \cdot a}$与$x_a$之间的独立性。根据定理二的内容，可以通过如下推导证明$x_{b \cdot a}$与$x_a$相互独立，即$ x_{b \cdot a} \perp x_a$。

根据式(10)和式(5)可知：
$$
\begin{equation}
    \begin{aligned}
        &x_{b \cdot a} =
        \begin{bmatrix}
            -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
        \end{bmatrix} X
        = M X \\
        &x_a =
        \begin{bmatrix}
            I_m & 0
        \end{bmatrix} X
        = N X
    \end{aligned}
\end{equation}
$$

于是可进一步推导：
$$
\begin{equation}
    M \Sigma N^{\top} =
    \begin{bmatrix}
        -\Sigma_{ba} \Sigma_{aa}^{-1} & I_n
    \end{bmatrix}
    \begin{bmatrix}
        \Sigma_{aa} & \Sigma_{ab} \\
        \Sigma_{ba} & \Sigma_{bb}
    \end{bmatrix}
    \begin{bmatrix}
        I_m \\ 0
    \end{bmatrix} = 0
\end{equation}
$$

因此，根据定理二可知$x_{b \cdot a}$与$ x_a$相互独立。于是，条件随机变量满足如下公式：
$$
\begin{equation}
    x_{b \cdot a} | x_a = x_{b \cdot a}
\end{equation}
$$

因此，由式(9)构造的特殊随机变量可得条件随机变量$ x_b | x_a$为：
$$
\begin{equation}
    \begin{aligned}
        x_b | x_a &= x_{b \cdot a} | x_a + \Sigma_{ba} \Sigma_{aa}^{-1} x_a | x_a \\
        &= x_{b \cdot a} + \Sigma_{ba} \Sigma_{aa}^{-1} x_a
    \end{aligned}
\end{equation}
$$

基于式(20)，可推导条件随机变量$x_b | x_a$的均值：
$$
\begin{equation}
    \begin{aligned}
        \mathbb{E}[x_b | x_a] &= \mathbb{E}\left[ x_{b \cdot a} + \textcolor{red}{\Sigma_{ba} \Sigma_{aa}^{-1} x_a} \right] \\
        &= \mu_{b \cdot a} + \textcolor{red}{\Sigma_{ba} \Sigma_{aa}^{-1} x_a}
    \end{aligned}
\end{equation}
$$

其中，因为$x_a$是条件，所以$\textcolor{red}{\Sigma_{ba} \Sigma_{aa}^{-1} x_a}$这一项是常量，其均值就是自身。

条件随机变量$x_b | x_a$的方差如下：
$$
\begin{equation}
    \begin{aligned}
        \mathbb{D}[x_b | x_a] &= \mathbb{D}\left[ x_{b \cdot a} + \textcolor{red}{\Sigma_{ba} \Sigma_{aa}^{-1} x_a} \right] \\
        &= \Sigma_{bb \cdot a}
    \end{aligned}
\end{equation}
$$

其中，因为$\textcolor{red}{\Sigma_{ba} \Sigma_{aa}^{-1} x_a}$这一项是常量，其方差为0。

综上所述，条件随机变量$x_b | x_a$满足如下分布：
$$
\begin{equation}
    x_b | x_a \sim N(\mu_b + \Sigma_{ba} \Sigma_{aa}^{-1} x_a, \Sigma_{bb \cdot a})
\end{equation}
$$

同理可得$x_a | x_b$满足如下分布：
$$
\begin{equation}
    x_a | x_b \sim N(\mu_a + \Sigma_{ab} \Sigma_{bb}^{-1} x_b, \Sigma_{aa \cdot b})
\end{equation}
$$

其中，
$$
\begin{equation}
    \begin{aligned}
        &\boxed{\mu_{a \cdot b} = -\Sigma_{ab} \Sigma_{bb}^{-1} \mu_b + \mu_a} \\
        &\boxed{\Sigma_{aa \cdot b} = \Sigma_{aa} - \Sigma_{ab} \Sigma_{bb}^{-1} \Sigma_{ba}}
    \end{aligned}
\end{equation}
$$

# 参考文献

[1]Bilibili《白板推导机器学习》系列

[2]C. M. Bishop. 《Pattern recognition and machine learning》